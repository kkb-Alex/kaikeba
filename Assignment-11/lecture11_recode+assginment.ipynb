{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut Rod Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_price = [1, 5, 8, 9, 10, 17, 17, 20, 24, 30, 35]\n",
    "price = defaultdict(int)\n",
    "for i, p in enumerate(original_price):\n",
    "    price[i+1] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import wraps # 用来还原原来的方法名\n",
    "def memo(f):\n",
    "    memo.already_computed = {}\n",
    "    # @wraps(f)\n",
    "    def wrapper(arg):\n",
    "        result = None\n",
    "        \n",
    "        if arg in memo.already_computed:\n",
    "            result = memo.already_computed[arg]\n",
    "        else:\n",
    "            result = f(arg)\n",
    "            memo.already_computed[arg] = result\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_revenue(n):\n",
    "    \"\"\"\n",
    "    Args: n is the iron length\n",
    "    Returns: the max revenue and the cut method\n",
    "    \"\"\"\n",
    "    solution = {} # record all best cut solution for 1-n length\n",
    "    \n",
    "    @memo\n",
    "    def cut(n):\n",
    "        max_price, max_split = max(\n",
    "            [(price[n], 0)] + [(cut(i) + cut(n-i), i) for i in range(1, n)], key=lambda x: x[0]\n",
    "        )\n",
    "        solution[n] = (n - max_split, max_split)\n",
    "        return max_price\n",
    "    \n",
    "    def parse_solution(n):\n",
    "        l_split, r_split = solution[n]\n",
    "        \n",
    "        if r_split == 0: return [l_split]\n",
    "        \n",
    "        return parse_solution(l_split) + parse_solution(r_split)\n",
    "    \n",
    "    revenue = cut(n)\n",
    "    cutted = parse_solution(n)\n",
    "    \n",
    "    # printout the result\n",
    "    cutted_d = {}\n",
    "    for c in cutted:\n",
    "        if c not in cutted_d:\n",
    "            cutted_d[c] = 1\n",
    "        else:\n",
    "            cutted_d[c] += 1\n",
    "    print('The max revenue of {} length iron is {}'.format(n, revenue))\n",
    "    print('The cut method is: ' + ','.join(\n",
    "            ['{}*{}'.format(c, cutted_d[c]) for c in sorted(cutted_d.keys(), reverse=True)])\n",
    "          )\n",
    "    \n",
    "    return revenue, cutted_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max revenue of 20 length iron is 60\n",
      "The cut method is: 11*1,6*1,3*1\n"
     ]
    }
   ],
   "source": [
    "revenue, cutted = max_revenue(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max revenue of 60 length iron is 188\n",
      "The cut method is: 11*5,3*1,2*1\n"
     ]
    }
   ],
   "source": [
    "revenue, cutted = max_revenue(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max revenue of 54 length iron is 170\n",
      "The cut method is: 11*4,10*1\n"
     ]
    }
   ],
   "source": [
    "revenue, cutted = max_revenue(54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(s1, s2):\n",
    "    \n",
    "    best_solutions = {}\n",
    "    \n",
    "    @lru_cache(maxsize=2**10)\n",
    "    def ed(s1, s2, tail=''):\n",
    "        \n",
    "        if len(s1) == 0: return len(s2)\n",
    "        if len(s2) == 0: return len(s1)\n",
    "        \n",
    "        tail_s1 = s1[-1]\n",
    "        tail_s2 = s2[-1]\n",
    "        \n",
    "        # use tail to record the removed tail\n",
    "        candidates = [\n",
    "            (ed(s1[:-1], s2, tail) + 1, 'DEL {} at position {}'.format(tail_s1, len(s1)), tail),\n",
    "            # string1 delete tail\n",
    "            (ed(s1, s2[:-1], tail_s2 + tail) + 1, 'ADD {} at position {}'.format(tail_s2, len(s1)+1), tail_s2 + tail)\n",
    "            # string1 add the tail of string2\n",
    "        ]\n",
    "        \n",
    "        if tail_s1 == tail_s2:\n",
    "            both_forward = (ed(s1[:-1], s2[:-1], tail_s2 + tail) + 0, '', tail_s2 + tail)\n",
    "        else:\n",
    "            both_forward = (ed(s1[:-1], s2[:-1], tail_s2 + tail) + 1, \n",
    "                            'SUB {} => {} at position {}'.format(tail_s1, tail_s2, len(s1)), tail_s2 + tail)\n",
    "            \n",
    "        candidates.append(both_forward)\n",
    "        \n",
    "        min_distance, operation, tail = min(candidates, key=lambda x: x[0])\n",
    "        \n",
    "        best_solutions[(s1, s2)] = [operation, tail]\n",
    "        \n",
    "        return min_distance\n",
    "    \n",
    "    solution = []\n",
    "    \n",
    "    def parse_solution(s1, s2):\n",
    "        if (s1, s2) in best_solutions:\n",
    "            operation, tail = best_solutions[(s1, s2)]\n",
    "            if operation.startswith('D'):\n",
    "                solution.append('({:<10}, {}): {}'.format(s1+tail, s2+tail, operation))\n",
    "                return parse_solution(s1[:-1], s2)\n",
    "            elif operation.startswith('A'):\n",
    "                solution.append('({:<10}, {}): {}'.format(s1+tail[1:], s2+tail[1:], operation))\n",
    "                return parse_solution(s1, s2[:-1])\n",
    "            elif operation.startswith('S'):\n",
    "                solution.append('({:<10}, {}): {}'.format(s1+tail[1:], s2+tail[1:], operation))\n",
    "                return parse_solution(s1[:-1], s2[:-1])\n",
    "            else:\n",
    "                return parse_solution(s1[:-1], s2[:-1])\n",
    "    \n",
    "    min_distance = ed(s1, s2)\n",
    "    parse_solution(s1, s2)\n",
    "    solution.append('({:<10}, {}): {}'.format(s2, s2, 'Done'))\n",
    "    \n",
    "    return min_distance, solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, solution = edit_distance('ABCDE', 'ADEEFG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(ABCDE     , ADEEFG): ADD G at position 6',\n",
       " '(ABCDEG    , ADEEFG): ADD F at position 6',\n",
       " '(ABCDEFG   , ADEEFG): ADD E at position 6',\n",
       " '(ABCDEEFG  , ADEEFG): DEL C at position 3',\n",
       " '(ABDEEFG   , ADEEFG): DEL B at position 2',\n",
       " '(ADEEFG    , ADEEFG): Done']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinyin Auto Correction Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Recode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_dataset = '../lecture1/article_9k.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(chinese_dataset).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(text):\n",
    "    # list all the chinese characters\n",
    "    return ''.join(re.findall('[\\u4e00-\\u9fff]', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHINESE_CHARACTERS = tokens(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30365478"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CHINESE_CHARACTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ni hao'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinyin.get('你好', format='strip', delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese2pinyin(character):\n",
    "    return pinyin.get(character, format='strip', delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHINESE_PINYIN_COPYS = chinese2pinyin(CHINESE_CHARACTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123312338"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CHINESE_PINYIN_COPYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHINESE_PINYIN_TOKENS = CHINESE_PINYIN_COPYS.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30365478"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CHINESE_PINYIN_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINYIN_COUNT = Counter(CHINESE_PINYIN_TOKENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct the splitted words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    # Prefer edit distance 0, then 1, then 2; otherwise default to word itself\n",
    "    \n",
    "    candidate = (known(edits0(word)) or\n",
    "                 known(edits1(word)) or\n",
    "                 known(edits2(word)) or\n",
    "                 [word])\n",
    "    return max(candidate, key=PINYIN_COUNT.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    return {w for w in words if w in PINYIN_COUNT}\n",
    "\n",
    "def edits0(word):\n",
    "    # return word itself (0 edit distance)\n",
    "    return {word}\n",
    "\n",
    "def edits1(word):\n",
    "    # return all strings that are 1 edit away from this pinyin\n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word):\n",
    "    # return all strings that are 2 eidts awat from this pinyin\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}\n",
    "\n",
    "def splits(word):\n",
    "    # return a list of all possible (first, rest) pairs that comprise pinyin\n",
    "    return [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sequence_pinyin(text_pinyin):\n",
    "    return ' '.join(map(correct, text_pinyin.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zhe shi yi ge ce shi'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sequence_pinyin('zhe sih yi ge ce sho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Homework Question ---> auto split the pinyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_unsplitted_string(string, score_func):\n",
    "    solution = {}\n",
    "    @lru_cache(maxsize=2**10)\n",
    "    def cut_string(string):\n",
    "        best_split = max(\n",
    "            [correct(string)] + [cut_string(string[:i])+' '+cut_string(string[i:]) for i in range(1, min(6, len(string)))],\n",
    "            key = lambda x: score_func(x)\n",
    "        )\n",
    "        solution[string] = best_split\n",
    "        return best_split\n",
    "\n",
    "    return cut_string(string), solution\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_word = CHINESE_PINYIN_TOKENS\n",
    "two_words = [one_word[i] + ' ' + one_word[i+1] for i in range(len(one_word)-1)]\n",
    "one_count = PINYIN_COUNT\n",
    "two_count = Counter(two_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取频次的函数\n",
    "def get_gram_count(word, wc):\n",
    "    if word in wc: return wc[word]\n",
    "    else:\n",
    "        return wc.most_common()[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two gram language model\n",
    "def two_gram_model(tokens):\n",
    "    \n",
    "    probability = 1\n",
    "    \n",
    "    for i in range(len(tokens)-1):\n",
    "        word = tokens[i]\n",
    "        next_w = tokens[i+1]\n",
    "        \n",
    "        two_gram_c = get_gram_count(word+' '+next_w, two_count)\n",
    "        one_gram_c = get_gram_count(next_w, one_count)\n",
    "        pro = two_gram_c / one_gram_c\n",
    "        \n",
    "        probability *= pro\n",
    "        \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 13s, sys: 1.36 s, total: 2min 14s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c, s = correct_unsplitted_string('zhesihyigecesho', score_func=two_gram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zi he si shi yi ci shi'"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果不太好，而且时间消耗比较高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.69602573881772e-13"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_gram_model('zi he si shi yi ci shi'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.324734771262851e-10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_gram_model('zhe shi yi ge ce shi'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用2gram模型应该是可以提取出更优的分割+修正情况，添加一个编辑距离的惩罚项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_2(string, score_func):\n",
    "    solution = {}\n",
    "    @lru_cache(maxsize=2**10)\n",
    "    def cut_string(string):\n",
    "        best_split = max(\n",
    "            [correct(string)] + [cut_string(string[:i])+' '+cut_string(string[i:]) for i in range(1, min(6, len(string)))],\n",
    "            key = lambda x: score_func(x) / (edit_distance(''.join(x), string)[0]+1)\n",
    "        )\n",
    "        solution[string] = best_split\n",
    "        return best_split\n",
    "\n",
    "    return cut_string(string), solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 55s, sys: 805 ms, total: 1min 55s\n",
      "Wall time: 1min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'zhi hyige ci shi'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_2('zhesihyigecesho', two_gram_model)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实我觉得这个切分不应该是通过2-gram模型取最大概率的那个结果，因为根据correct函数，correct('shi')可能会返回'chi', 'si'，而如果切分的话，本来正确的'hua'可能会被切分成'h'+'ua',经过correct变成'ha','ha'，最后的评分可能比正确的更高。因此下面改变一下思路，用以下规则来切分\n",
    ">1. 总编辑距离最小\n",
    "2. 切分时优先选择长度大的，比如说'shuang'，可以切分成'shu'+'ang'，但是这里优先切分为'shuang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_3(string):\n",
    "    solution = {}\n",
    "    @lru_cache(maxsize=2**10)  \n",
    "    def cut_string(string):\n",
    "        candidates = [cut_string(string[:i])+' '+cut_string(string[i:]) for i in range(1, min(6, len(string)))]\n",
    "        if len(string) <= 6:\n",
    "            candidates.append(string)\n",
    "        splitted = min(candidates, key=lambda x: correct_words(x)[0]+len(x.split()))\n",
    "        solution[string] = splitted\n",
    "        return splitted\n",
    "    \n",
    "    def correct_words(string):\n",
    "        distance = 0\n",
    "        corrected = []\n",
    "        words = string.split()\n",
    "        for word in words:\n",
    "            c, d = correct_one_word(word)\n",
    "            corrected.append(c)\n",
    "            distance += d\n",
    "        return distance, corrected\n",
    "    \n",
    "    def correct_one_word(word):\n",
    "        if word in PINYIN_COUNT:\n",
    "            return (word, 0)\n",
    "        else:\n",
    "            e1 = known(edits1(word))\n",
    "            if e1:\n",
    "                return (max(e1, key=PINYIN_COUNT.get), 1)\n",
    "            else:\n",
    "                e2 = known(edits2(word))\n",
    "                if e2:\n",
    "                    return (max(e2, key=PINYIN_COUNT.get), 2)\n",
    "                else:\n",
    "                    return (word, 10)\n",
    "                \n",
    "    splitted = cut_string(string)\n",
    "    \n",
    "    return ' '.join(correct_words(splitted)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.24 s, sys: 29.2 ms, total: 2.26 s\n",
      "Wall time: 2.35 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'zhe si yi ge ce shi'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_3('zhesihyigecesho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 s, sys: 16.9 ms, total: 1.45 s\n",
      "Wall time: 1.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'zhe guo zuo ye hao na hua'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_3('zhegozuoyehaonaua')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，通过对编辑距离的约束，切分效果已经不错，能最大限度保留没有拼错的词，但是对整体的语义没做到很好的筛选。<br>\n",
    "我试过把2-gram和编辑距离约束结合起来，但是测试了之后花的时间太长，完全不像现有的输入法这样识别能力强并且耗时低。在网上也没有xian"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
