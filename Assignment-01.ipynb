{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 今天是2019年9月28日，今天世界上又多了一名AI工程师 :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 minchuian.gao@gmail.com 中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    2.2. what problems do you want to solve？\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    2.5. How will you plan to study in this course period?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至minchuian.gao@gmail.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.10.8日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "智能客服；自动驾驶；游戏AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "1.用Github来存储代码，上交作业\n",
    "2.Jupyter可以用来创建文档和分享文档，并且能测试特定的代码块，非常方便；Pycharm也是我第一次接触Python使用的IDE，总体来说Pycharm的集成做的很好，具备各种实用的功能，比如代码补齐等。虽然我最近也开始在尝试使用VSCode，在轻量级的代码运行上还是VSCode比较舒服，不需要加载很多东西，但是如果是项目级别的代码，还是用Pycharm更加好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "概率模型是指用数学方法来描述一个随机现象，由样本区间，样本区间内所有可能事件及事件发生的概率组成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1.彩票\n",
    "2.支付随机减免\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "因为文字语言在描述上并不是唯一的，而且容易出现错误，语法树/自动机这类方式生成的语言无法很好的处理输入错误这种情况。而用概率模型能在一定程度上识别处理错误的输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "语言模型就是用来计算一个句子的概率的模型，也就是判断一句话是否合理的概率，最常用的是N-gram model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "语音识别、机器翻译、自动分词、搜索引擎等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "输入中的任何词都互不依赖，相互独立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "优势：训练速度快、可靠性高\n",
    "劣势：辨别性差、精度低"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "一个词的出现依赖于它前面出现的一个词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1569578233461&di=4adfa7597fb380e7cc0e67190bbd7605&imgtype=0&src=http%3A%2F%2Fs1.sinaimg.cn%2Flarge%2F006eYYfyzy76cmpG3Yb1f)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOBA AI\n",
    "action = '''\n",
    "ACTION = HERO DOING WHERE \n",
    "HERO = CHARACTER NAME\n",
    "CHARACTER = Core | Mid | Offlane | Support\n",
    "NAME = Robot NUM\n",
    "NUM = 1 | 2 | 3 | 4 | 5\n",
    "DOING = Gank | Help | Push\n",
    "WHERE = Top | Mid | Bottom | Jungle\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 便利店售货员\n",
    "saler = '''\n",
    "saler = 问候 报价 支付 结语\n",
    "问候 = 欢迎光临！ | 您好！\n",
    "报价 = 单价 | 报价 单价\n",
    "单价 = 商品名 价格 元；\n",
    "商品名 = 热狗 | 面包 | 饮料 | 薯片 | 纸巾\n",
    "价格 = 5 | 10 | 15 | 20 | 25\n",
    "支付 = 请出示 支付方式 条形码。\n",
    "支付方式 = 微信 | 支付宝\n",
    "结语 = 欢迎下次光临! | 欢迎下次再来!\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate(rules, target):\n",
    "    if target in rules:\n",
    "        expr = random.choice(rules[target])  #随机取一个表达\n",
    "        return ''.join([generate(rules, target=s.strip()) for s in expr.split()])\n",
    "    else:\n",
    "        return target\n",
    "        \n",
    "def get_grammar(grammar, stmt_split = '=', or_split = '|'):\n",
    "    gram = dict() # 初始化字典\n",
    "    \n",
    "    for line in grammar.split('\\n'):\n",
    "        if not line:\n",
    "            continue\n",
    "        stmt, exprs = line.split(stmt_split)\n",
    "        gram[stmt.strip()] = [expr.strip() for expr in exprs.split(or_split)]\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欢迎光临！面包10元；热狗10元；面包5元；热狗10元；面包15元；请出示微信条形码。欢迎下次光临!\n"
     ]
    }
   ],
   "source": [
    "gram = get_grammar(saler)\n",
    "print(generate(gram, 'saler'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(rules, target, reps):\n",
    "    for _ in range(reps):\n",
    "        yield(generate(rules, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！薯片20元；纸巾25元；请出示支付宝条形码。欢迎下次光临!\n",
      "您好！饮料25元；请出示支付宝条形码。欢迎下次光临!\n",
      "您好！纸巾20元；请出示微信条形码。欢迎下次再来!\n",
      "欢迎光临！纸巾25元；请出示支付宝条形码。欢迎下次光临!\n",
      "您好！纸巾25元；请出示支付宝条形码。欢迎下次再来!\n",
      "您好！薯片15元；薯片5元；纸巾25元；纸巾15元；面包15元；请出示微信条形码。欢迎下次光临!\n",
      "您好！薯片25元；饮料5元；请出示支付宝条形码。欢迎下次再来!\n",
      "欢迎光临！热狗15元；请出示支付宝条形码。欢迎下次光临!\n",
      "欢迎光临！饮料25元；热狗20元；请出示微信条形码。欢迎下次再来!\n",
      "欢迎光临！热狗5元；请出示微信条形码。欢迎下次光临!\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate_n(gram, 'saler', 10):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文本数据源清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取\n",
    "insurance = open('train.txt').read()\n",
    "comments = open('movie_comments.csv').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1343520"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(insurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26783085"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 ++$++ disability-insurance ++$++ 法律要求残疾保险吗？ ++$++ Is  Disability  Insurance  Required  By  Law?\\n1 ++$++ life-insurance ++$++ 债权人可以在死后人寿保险吗？ ++$++ Can  Creditors  Take  Life  Insurance  After  Death?\\n2 ++$++ renters-insurance ++$++ 旅行者保险有租赁保险吗？ ++$++ Does  Travelers  Insurance  Have  Renters  Insurance?\\n3 ++$++ auto-insurance ++$++ 我可以开一辆没有保险的新车吗？ ++$++ Can  I  Drive  A  New  Car  Home  Without  Insurance?\\n4 ++$++ life-insurance ++$++ 人寿保险的现金转出价值是否应纳税？ ++$++ Is  The  Cash  Surrender  Value  Of '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id,link,name,comment,star\\n1,https://movie.douban.com/subject/26363254/,战狼2,吴京意淫到了脑残的地步，看了恶心想吐,1\\n2,https://movie.douban.com/subject/26363254/,战狼2,首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮番上场，视物理逻辑于不顾，不得不说有钱真好，随意胡闹,2\\n3,https://movie.douban.com/subject/26363254/,战狼2,吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋律，为了煽情而煽情，让人觉得他是个大做作、大谎言家。（7.29更新）片子整体不如湄公河行动，1.整体不够流畅，编剧有毒，台词尴尬；2.刻意做作的主旋律煽情显得如此不合时宜而又多余。,2\\n4,https://movie.douban.com/subject/26363254/,战狼2,凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。,4\\n5,https://m'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清洗文本，只保留文字和数字\n",
    "import re\n",
    "\n",
    "def preprocess(corpus):\n",
    "    return re.sub(r'[^\\w]', '', corpus)\n",
    "\n",
    "insur_c = preprocess(insurance)\n",
    "comm_c = preprocess(comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0disabilityinsurance法律要求残疾保险吗IsDisabilityInsuranceRequiredByLaw1lifeinsurance债权人可以在死后人寿保险吗CanCreditorsTakeLifeInsuranceAfterDeath2rentersinsurance旅行者保险有租赁保险吗DoesTravelersInsuranceHaveRentersInsurance3autoinsurance我可以开一辆没有保险的新车吗CanIDriveANewCarHomeWithoutInsurance4lifeinsurance人寿保险的现金转出价值是否应纳税IsTheCashSurrenderValueOfLifeInsuranceTaxable5annuities如何报告年金收入HowIsAnnuityIncomeReported6homeinsuranceAAA家庭保险涵盖什么WhatDoesAAAHomeInsuranceCover7retirementplans什么是简单的退休计划WhatIsASimpleRetirementPlan8disability'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insur_c[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "856288 21804490\n"
     ]
    }
   ],
   "source": [
    "print(len(insur_c), len(comm_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 切词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/qn/yh63v8fn5fd2l36nndjc3tw80000gn/T/jieba.cache\n",
      "Loading model cost 1.580 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "insur_tokens = cut(insur_c)\n",
    "comm_tokens = cut(comm_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87967 5782836\n"
     ]
    }
   ],
   "source": [
    "print(len(insur_tokens), len(comm_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 建立2-gram模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "insur_count = Counter(insur_tokens)\n",
    "comm_count = Counter(comm_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('保险', 5013),\n",
       " ('的', 3220),\n",
       " ('人寿保险', 2962),\n",
       " ('什么', 2677),\n",
       " ('吗', 2479),\n",
       " ('是', 2347),\n",
       " ('我', 2054),\n",
       " ('是否', 1862),\n",
       " ('可以', 1704),\n",
       " ('健康', 1513)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insur_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 357642),\n",
       " ('了', 103946),\n",
       " ('是', 75282),\n",
       " ('我', 57520),\n",
       " ('都', 36756),\n",
       " ('很', 34791),\n",
       " ('和', 34261),\n",
       " ('电影', 33983),\n",
       " ('看', 33912),\n",
       " ('在', 33780)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得语料库的2-words counts\n",
    "def two_words_count(tokens):\n",
    "    two_gram_words = [tokens[i] + tokens[i+1] for i in range(len(tokens)-1)]\n",
    "    return Counter(two_gram_words)\n",
    "insur_two_words_c = two_words_count(insur_tokens)\n",
    "comm_two_words_c = two_words_count(comm_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('健康保险', 1349),\n",
       " ('什么是', 1149),\n",
       " ('保险是否', 958),\n",
       " ('我的', 726),\n",
       " ('残疾保险', 659),\n",
       " ('房主保险', 603),\n",
       " ('我可以', 529),\n",
       " ('保险吗', 511),\n",
       " ('是否覆盖', 504),\n",
       " ('家庭保险', 440)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insur_two_words_c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 统计1-gram和2-gram的函数\n",
    "def get_one_gram_count(word, words_count):\n",
    "    if word in words_count: return words_count[word]\n",
    "    else:\n",
    "        return words_count.most_common()[-1][-1]\n",
    "def get_two_gram_count(word, two_words_count):\n",
    "    if word in two_words_count: return two_words_count[word]\n",
    "    else:\n",
    "        return two_words_count.most_common()[-1][-1]\n",
    "# test\n",
    "print(get_one_gram_count('午饭', insur_count))\n",
    "print(get_two_gram_count('我饿了', comm_two_words_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two gram model\n",
    "def two_gram_model(sentence, words_count, two_words_count):\n",
    "    tokens = cut(sentence)\n",
    "    \n",
    "    probability = 1\n",
    "    \n",
    "    for i in range(len(tokens)-1):\n",
    "        word = tokens[i]\n",
    "        next_word = tokens[i+1]\n",
    "        \n",
    "        two_gram_count = get_two_gram_count(word+next_word, two_words_count)\n",
    "        one_gram_count = get_one_gram_count(next_word, words_count)\n",
    "        pro = two_gram_count / one_gram_count\n",
    "        \n",
    "        probability *= pro\n",
    "    \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！纸巾5元；请出示支付宝条形码。欢迎下次再来! 0.016129032258064516\n",
      "您好！薯片20元；请出示微信条形码。欢迎下次再来! 0.005376344086021505\n",
      "您好！薯片10元；薯片20元；饮料15元；请出示微信条形码。欢迎下次再来! 0.00021505376344086021\n",
      "您好！薯片5元；饮料10元；薯片25元；请出示微信条形码。欢迎下次光临! 0.014285714285714285\n",
      "您好！热狗20元；请出示支付宝条形码。欢迎下次光临! 0.16666666666666666\n",
      "您好！面包20元；面包20元；请出示微信条形码。欢迎下次再来! 0.0008960573476702508\n",
      "您好！热狗5元；请出示微信条形码。欢迎下次再来! 0.016129032258064516\n",
      "您好！纸巾20元；薯片20元；面包5元；面包10元；热狗20元；薯片15元；薯片5元；请出示支付宝条形码。欢迎下次光临! 4.62962962962963e-05\n",
      "欢迎光临！饮料25元；请出示支付宝条形码。欢迎下次光临! 0.14285714285714285\n",
      "欢迎光临！饮料5元；请出示支付宝条形码。欢迎下次光临! 0.5\n",
      "\n",
      "欢迎光临！纸巾10元；热狗20元；请出示微信条形码。欢迎下次光临! 6.513287947598579e-21\n",
      "您好！薯片10元；纸巾5元；薯片25元；请出示支付宝条形码。欢迎下次再来! 6.434298950625227e-30\n",
      "欢迎光临！面包10元；请出示微信条形码。欢迎下次光临! 1.7776082606817486e-15\n",
      "欢迎光临！薯片25元；请出示支付宝条形码。欢迎下次光临! 1.9113254894595806e-13\n",
      "您好！薯片20元；请出示微信条形码。欢迎下次再来! 1.6883553267117823e-20\n",
      "您好！饮料25元；纸巾20元；请出示支付宝条形码。欢迎下次光临! 6.450350558442009e-20\n",
      "您好！热狗5元；薯片20元；薯片15元；面包15元；薯片5元；薯片5元；请出示微信条形码。欢迎下次光临! 1.4769805156939538e-42\n",
      "欢迎光临！饮料20元；请出示支付宝条形码。欢迎下次光临! 7.33675773218311e-14\n",
      "您好！面包5元；热狗25元；面包20元；请出示微信条形码。欢迎下次光临! 1.130760566360771e-27\n",
      "您好！热狗20元；请出示微信条形码。欢迎下次光临! 2.821829896993504e-15\n"
     ]
    }
   ],
   "source": [
    "def test_model(words_count, two_words_count):\n",
    "    sentence = generate(gram, 'saler')\n",
    "    pro = two_gram_model(sentence, words_count, two_words_count)\n",
    "    print(sentence, pro)\n",
    "for _ in range(10):\n",
    "    test_model(insur_count, insur_two_words_c)\n",
    "print()\n",
    "for _ in range(10):\n",
    "    test_model(comm_count, comm_two_words_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于comments语料库太大，运行速度比较慢，这里只使用insurance语料库\n",
    "def generate_best(rules, target, model, n): # you code here\n",
    "    res = []\n",
    "    \n",
    "    for sentence in generate_n(rules, target, n):\n",
    "        pro = model(sentence, insur_count, insur_two_words_c)\n",
    "        res.append((sentence, pro))\n",
    "    return sorted(res, key=lambda x:x[-1], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('欢迎光临！面包5元；请出示支付宝条形码。欢迎下次再来!', 0.016129032258064516)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(gram, 'saler', two_gram_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('您好！面包5元；请出示微信条形码。欢迎下次光临!', 0.5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(gram, 'saler', two_gram_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('欢迎光临！热狗5元；请出示支付宝条形码。欢迎下次光临!', 0.5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(gram, 'saler', two_gram_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('您好！薯片10元；请出示支付宝条形码。欢迎下次光临!', 0.2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(gram, 'saler', two_gram_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('您好！饮料25元；请出示支付宝条形码。欢迎下次光临!', 0.14285714285714285)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(gram, 'saler', two_gram_model, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1. 语法树模型在复杂场景下编写起来很困难。比如说一个DOTA2 AI的行为，可以是补兵，A人，gank，推塔，求助，撤退，攻击Roshan等等。\n",
    "2. 在我写的pro模型中，代码结构还可以有比较大的提升。比如说，我们只输入语料库就能生成一个2-gram模型，这样的话切换预料库的时候不需要重复的输入word_count, two_words_count，让代码更加干净。\n",
    "3. generate_best模型中还存在一个问题，假如我们输入的模型是three_gram_model,那么这样的话又需要重新修改best里面的代码；更好的方式应该是无聊2-gram还是3-gram都只接受语料库一个参数，这样的话就能在不修改generate-best模型的情况下更换pro模型；但是实际上这样子还是会存在问题，如果我们重复使用generate_best模型，每次都需要重新加载语料库，运行速度会大大降低。综上考虑，最好还是写一个class，这个class可以进行语料库加载，pro模型选择，然后内置generate_best函数来调用已经加载的语料库和pro模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
